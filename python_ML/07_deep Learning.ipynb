{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "1.0874467\n",
      "0.62030375\n",
      "0.5239312\n",
      "0.47458062\n",
      "0.43655837\n",
      "0.40491945\n",
      "0.37802607\n",
      "0.3548587\n",
      "0.3346709\n",
      "0.31689894\n",
      "정확도 : [1.0]\n"
     ]
    }
   ],
   "source": [
    "## Deep Learning\n",
    "\n",
    "# logistic regression을 이용하여 AND 연산을 학습\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# training data set\n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "\n",
    "y_data = [[0],[0],[0],[1]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "# train node\n",
    "# train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "    if step % 300 == 0:\n",
    "        print(cost_val)     \n",
    "        \n",
    "# Accuracy 측정 \n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict,Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run([accuracy], feed_dict={X:x_data, Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3675065\n",
      "0.6925141\n",
      "0.6671529\n",
      "0.624359\n",
      "0.5427338\n",
      "0.42042732\n",
      "0.2887126\n",
      "0.19071506\n",
      "0.13101208\n",
      "0.09545102\n",
      "정확도 : [1.0]\n"
     ]
    }
   ],
   "source": [
    "## Deep Learning\n",
    "\n",
    "# NN(Neural Network)을 이용하여 XOR 연산을 학습\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# training data set( XOR에 대한 진리표)\n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "\n",
    "y_data = [[0],[1],[1],[0]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "# 첫번째 레이어\n",
    "W1 = tf.Variable(tf.random_normal([2,8]), name=\"weight1\") # ([2,?]) : ? : 두번째레이어의 몇개의 input을 사용할껀지\n",
    "b1 = tf.Variable(tf.random_normal([8]), name=\"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "# 두번째 레이어\n",
    "W2 = tf.Variable(tf.random_normal([8,1]), name=\"weight2\") \n",
    "b2 = tf.Variable(tf.random_normal([1]), name=\"bias2\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(layer1,W2) + b2\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "# train node\n",
    "# train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "    if step % 3000 == 0:\n",
    "        print(cost_val)     \n",
    "        \n",
    "# Accuracy 측정 \n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict,Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run([accuracy], feed_dict={X:x_data, Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6141b2bedbed>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "55000\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "56.34009\n",
      "27.866474\n",
      "3.0738087\n",
      "6.5800395\n",
      "2.0089886\n",
      "0.2686798\n",
      "0.3826184\n",
      "0.0\n",
      "0.0\n",
      "0.4601483\n",
      "정확도 :[0.9576]\n"
     ]
    }
   ],
   "source": [
    "## NNIST (Neural Network)\n",
    "## tensorflow에 example로 포함된 MNIST예제를 NN으로 학습.(accuracy => 95%)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) # 폴더를 만들고 데이터 저장 , 압축파일 파일 압축풀 필요없음\n",
    "\n",
    "# 데이터 확인\n",
    "print(mnist.train.num_examples) # 학습용 데이터의 개수 / 학습용 = train , 테스트용 = \n",
    "print(mnist.train.images.shape) # (55000, 784)\n",
    "                                #  28 X 28 이미지를 1차원 형태로 저장\n",
    "print(mnist.train.labels.shape)\n",
    "\n",
    "# plt.imshow(mnist.train.images[0].reshape(28,28), cmap=\"Greys\", interpolation=\"nearest\") # 1차원데이터를 2차원데이터로 변경\n",
    "# # 55000개의 그림중에 이미지를 선택해서 픽셀정보를 줘야한다.\n",
    "# plt.show()\n",
    "# print(mnist.train.labels[0])\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32) \n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W1 = tf.Variable(tf.random_normal([784,256]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1) + b1) # sigmoid대신 relu사용 :  값이 희미해지기 때문에 relu사용 / sigmoid : 0과 1사이  / softmax : 확률값\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,10]), name=\"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(layer2,W3) + b3  \n",
    "H = tf.nn.softmax(logits)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "# train node 생성\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train = optimizer.minimize(cost)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "# GradientDescentOptimizer 보다 효율 좋은 AdamOptimizer 사용  / learning_rate=0.01 => learning_rate=0.001\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\"\"\" \n",
    "사용하는 데이터의 크기가 상당히 크다.\n",
    "메모리의 문제때문에 한번에 불러올수 없다.\n",
    "데이터의 크기에 상관없이 학습하는 방식이 필요하다.!! => 잘라서 학습하는 방식으로 수행\n",
    "epoch : training data를 1번 학습시키는 것.\n",
    "\"\"\"\n",
    "# epoch 학습진행\n",
    "training_epoch = 30 # for 루프를 30만큼 돌린다는 의미\n",
    "batch_size = 100 #  55000개의 행을 다 읽어들이는게 아니라 100개의 행을 읽어서 반복학습!! (아중루프가 돔) / 얼마만큼의 사이즈로 불러드릴껀지\n",
    "\n",
    "for step in range(training_epoch): # 30 epoch 만큼 반복\n",
    "    num_of_iter = int(mnist.train.num_examples /  batch_size) # 550번 끊어 읽겠다는 의미\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size) \n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y})\n",
    "        \n",
    "    if step % 3 == 0:\n",
    "        print(cost_val)     \n",
    "\n",
    "# 학습진행\n",
    "# for step in range(3000):\n",
    "#     _, cost_val = sess.run([train,cost], feed_dict={X:mnist.train.images, Y:mnist.train.labels})\n",
    "    \n",
    "#     if step % 300 == 0:\n",
    "#         print(cost_val)\n",
    "\n",
    "# Accuracy(정확도) 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run([accuracy], feed_dict={X:mnist.test.images, Y:mnist.test.labels})\n",
    "\n",
    "print(\"정확도 :{}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "55000\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "0.12418873\n",
      "0.06924549\n",
      "0.051645197\n",
      "0.050949465\n",
      "0.0053187\n",
      "0.00036422478\n",
      "0.0024730668\n",
      "0.00020901799\n",
      "0.004437133\n",
      "0.0004658118\n",
      "정확도 :[0.9811]\n"
     ]
    }
   ],
   "source": [
    "## NNIST (Neural Network)\n",
    "## tensorflow에 example로 포함된 MNIST예제를 NN으로 학습.(accuracy => 95%)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading \n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) # 폴더를 만들고 데이터 저장 , 압축파일 파일 압축풀 필요없음\n",
    "\n",
    "# 데이터 확인\n",
    "print(mnist.train.num_examples) # 학습용 데이터의 개수 / 학습용 = train , 테스트용 = \n",
    "print(mnist.train.images.shape) # (55000, 784)\n",
    "                                #  28 X 28 이미지를 1차원 형태로 저장\n",
    "print(mnist.train.labels.shape)\n",
    "\n",
    "# plt.imshow(mnist.train.images[0].reshape(28,28), cmap=\"Greys\", interpolation=\"nearest\") # 1차원데이터를 2차원데이터로 변경\n",
    "# # 55000개의 그림중에 이미지를 선택해서 픽셀정보를 줘야한다.\n",
    "# plt.show()\n",
    "# print(mnist.train.labels[0])\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32) \n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias # weight값 초기화\n",
    "W1 = tf.get_variable(\"weight1\", shape=[784,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1) + b1) # sigmoid대신 relu사용 :  값이 희미해지기 때문에 relu사용 / sigmoid : 0과 1사이  / softmax : 확률값\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\",shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\",shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(layer2,W3) + b3  \n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "# train node 생성\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train = optimizer.minimize(cost)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "# GradientDescentOptimizer 보다 효율 좋은 AdamOptimizer 사용  / learning_rate=0.01 => learning_rate=0.001\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\"\"\" \n",
    "사용하는 데이터의 크기가 상당히 크다.\n",
    "메모리의 문제때문에 한번에 불러올수 없다.\n",
    "데이터의 크기에 상관없이 학습하는 방식이 필요하다.!! => 잘라서 학습하는 방식으로 수행\n",
    "epoch : training data를 1번 학습시키는 것.\n",
    "\"\"\"\n",
    "# epoch 학습진행\n",
    "training_epoch = 30 # for 루프를 30만큼 돌린다는 의미\n",
    "batch_size = 100 #  55000개의 행을 다 읽어들이는게 아니라 100개의 행을 읽어서 반복학습!! (아중루프가 돔) / 얼마만큼의 사이즈로 불러드릴껀지\n",
    "\n",
    "for step in range(training_epoch): # 30 epoch 만큼 반복\n",
    "    num_of_iter = int(mnist.train.num_examples /  batch_size) # 550번 끊어 읽겠다는 의미\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size) \n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y})\n",
    "        \n",
    "    if step % 3 == 0:\n",
    "        print(cost_val)     \n",
    "\n",
    "# 학습진행\n",
    "# for step in range(3000):\n",
    "#     _, cost_val = sess.run([train,cost], feed_dict={X:mnist.train.images, Y:mnist.train.labels})\n",
    "    \n",
    "#     if step % 300 == 0:\n",
    "#         print(cost_val)\n",
    "\n",
    "# Accuracy(정확도) 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run([accuracy], feed_dict={X:mnist.test.images, Y:mnist.test.labels})\n",
    "\n",
    "print(\"정확도 :{}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "(2, 2, 1, 3)\n",
      "(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "## 2019-07-17\n",
    "# Convolution example\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# imange의 형태\n",
    "# 1장의 이미지는 3차원 형태의 데이터\n",
    "# (이미지의 개수, width, height, color)\n",
    "# (1, 3, 3, 1)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "# filter를 준비해야한다. => 3차원 \n",
    "# (width, height, color, 필터의 개수) , 4차원\n",
    "# (2, 2, 1, 1)\n",
    "# 필터들의 집합 => weight\n",
    "weight = np.array([[[[1, -5, 10]],[[1, -5, 10]]],\n",
    "                   [[[1, -5, 10]],[[1, -5, 10]]]])\n",
    "print(weight.shape)\n",
    "\n",
    "# stride 지정 => 사실 2차원이면 되는데 행렬연산때문에 \n",
    "# (1, stride width, stride height, 1) => 4차원으로 표현\n",
    "# stride = [1,1,1,1]\n",
    "#                    (이미지,필터,)\n",
    "conv2d = tf.nn.conv2d(image,weight,strides=[1,1,1,1], padding=\"VALID\") \n",
    "# padding=\"VALID\": 이미지의 사이즈가 줄어든다. / padding=\"SAME\" :원본과 똑같이 맞추라는 의미\n",
    "print(conv2d.shape)\n",
    "# 하나의 이미지에 필터 3개를 적용시키면 (1, 2, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14, 14, 5)\n",
      "(5, 14, 14, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## mnist 예제를 이용해서 하나의 이미지에 대한\n",
    "## convolutional image 5개를 생성해보기!\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt # 일반적으로 그림그리는 모듈\n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) # y측 레이블이 one_hot형태로 나올수 있게 해줌\n",
    "\n",
    "# training 이미지 중 2번째 이미지의 정보를 얻어온다. 픽셀테이터 땡겨오는것\n",
    "img = mnist.train.images[1] # 1차원 데이터\n",
    "img = img.reshape(28,28)    # 2차원 데이터로 변환\n",
    "# print(img.shape) # 1차원의형태를 2차원의 형태로 변경해줘야한다.\n",
    "\n",
    "plt.imshow(img, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "# 해당 이미지를 convolution 이미지로 변경\n",
    "# 2차원 형태의 img를 4차원 형태의 img로 변환\n",
    "img = img.reshape(-1,28,28,1) # 가로,세로는 변하지 않고 흑백컬러1 / 이미지가 여러장이면 -1부분이 바뀌게 될것임.\n",
    "# img.shape\n",
    "# 이미지가 준비 되었으니 필터를 여러개 준비 (5개 정도)\n",
    "# 5개의 필터를 이용 , 2 x 2 짜리 필터를 이용\n",
    "# (2,2,1,5) 랜덤하게 만들꺼임\n",
    "W = tf.Variable(tf.random_normal([2,2,1,5]), name=\"filter\")\n",
    "conv2d = tf.nn.conv2d(img,W,strides=[1,2,2,1], padding=\"SAME\")\n",
    "# 2칸씩움직이는 stride / padding=\"SAME\" : 원본과 똑같은 이미지가 5개 생성\n",
    "print(conv2d.shape) # (1, 14, 14, 5) => 14 x 14 짜리 이미지가 5개 생성\n",
    "\n",
    "# 새로 생성된 이미지를 plt를 이용해서 확인\n",
    "sess = tf.Session() # sess.run을 해야지 배열값을 얻을수 있다.\n",
    "sess.run(tf.global_variables_initializer()) # 초기화\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# 배열의 축을 임의로 변경 (1, 14, 14, 5) => (5, 14, 14, 1) -> 루프를 돌리기 위해서 배열 축 임의로 변경 , 데이터를 쉽게 추출하기 위해서\n",
    "conv2d = np.swapaxes(conv2d,0,3) \n",
    "print(conv2d.shape) # (5, 14, 14, 1)\n",
    "\n",
    "fig,axes = plt.subplots(1,5) # 1행 5열짜리 subplot을 생성 / subplots : 그림을 여러개 그릴 수 있음\n",
    "                             # axes : 각각의 subplot의 배열\n",
    "for idx,item in enumerate(conv2d): # enumerate : 인덱스 번호와 컬렉션의 원소를 tuple형태로 반환\n",
    "    axes[idx].imshow(item.reshape(14,14), cmap=\"Greys\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 7, 7, 64)\n",
      "(?, 7, 7, 64)\n",
      "Wall time: 981 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 셀 수행하는 데 얼마나 걸리는지 출력하는거, 제일 상단에 있어야한다. %%time은 jupyter notebook에서만 돌아간당!!!\n",
    "#### MNIST with CNN\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "## 0. 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## 1. Data Loading & Data 정제\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "## 2. placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32) \n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32) \n",
    "drop_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "## 3. Convolution \n",
    "## 3.1 Convolution layer 1\n",
    "x_img =  tf.reshape(X,[-1,28,28,1]) # x에대한 shape를 변경해줄꺼임 2차원 -> 4차원 (이미지의 개수, 가로, 세로, 컬러)\n",
    "W1 = tf.Variable(tf.random_normal([2,2,1,32]), name=\"filter1\") # 2행 2열 색 32개의 필터\n",
    "L1 = tf.nn.conv2d(x_img,W1,strides=[1,2,2,1], padding=\"SAME\") # tf.nn.conv2d(입력이미지, 필터, stride=[],padding=\"\")\n",
    "                                                              #                               얼마만큼 움직일껀지\n",
    "print(L1.shape)  # (?, 14, 14, 32)\n",
    "\n",
    "# sigmoid는 할수록 값이 작아져서 0에 가까워지기 때문에 relu를 사용한다.\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") \n",
    "# tf.nn.max_pool(입력받을값,ksize=[],strides=[], padding=\"\") : 큰 데이터를 작은데이터로 줄이는 것\n",
    "print(L1.shape)  # (?, 7, 7, 32)\n",
    "\n",
    "## 3.2 Convolution layer 2\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64]), name=\"filter2\") # 3행 3열 색 64개의 필터 => 32 -> 입력으로 들어오는 형태 shape를 맞춰줘야함\n",
    "L2 = tf.nn.conv2d(L1,W2,strides=[1,1,1,1], padding=\"SAME\") # tf.nn.conv2d(입력이미지, 필터, stride=[],padding=\"\")\n",
    "                                                              #                               얼마만큼 움직일껀지\n",
    "print(L2.shape)  # (?, 7, 7, 64)\n",
    "\n",
    "# sigmoid는 할수록 값이 작아져서 0에 가까워지기 때문에 relu를 사용한다.\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "L2 = tf.nn.max_pool(L2,ksize=[1,1,1,1], strides=[1,1,1,1], padding=\"SAME\") \n",
    "# tf.nn.max_pool(입력받을값,ksize=[],strides=[], padding=\"\") : 큰 데이터를 작은데이터로 줄이는 것\n",
    "print(L2.shape)  # (?, 7, 7, 64) => ?는 이미지의 수\n",
    "\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "## 4. Neural Network\n",
    "## 4.1 Weight & bias\n",
    "W3 = tf.get_variable(\"weight3\", shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer()) # shape=[\"컬럼수\",\"아웃풋수\"] / 위에서는 필터의 형태로 잡기위해 tf.Variable()사용\n",
    "\n",
    "b3 = tf.Variable(tf.random_normal([]), name=\"bias3\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(layer2,W3) + b3  \n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "# train node 생성\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train = optimizer.minimize(cost)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "# GradientDescentOptimizer 보다 효율 좋은 AdamOptimizer 사용  / learning_rate=0.01 => learning_rate=0.001\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\"\"\" \n",
    "사용하는 데이터의 크기가 상당히 크다.\n",
    "메모리의 문제때문에 한번에 불러올수 없다.\n",
    "데이터의 크기에 상관없이 학습하는 방식이 필요하다.!! => 잘라서 학습하는 방식으로 수행\n",
    "epoch : training data를 1번 학습시키는 것.\n",
    "\"\"\"\n",
    "# epoch 학습진행\n",
    "training_epoch = 100 # for 루프를 30만큼 돌린다는 의미\n",
    "batch_size = 100 #  55000개의 행을 다 읽어들이는게 아니라 100개의 행을 읽어서 반복학습!! (아중루프가 돔) / 얼마만큼의 사이즈로 불러드릴껀지\n",
    "\n",
    "for step in range(training_epoch): # 30 epoch 만큼 반복\n",
    "    num_of_iter = int(mnist.train.num_examples /  batch_size) # 550번 끊어 읽겠다는 의미\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size) \n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y})\n",
    "        \n",
    "    if step % 10 == 0:\n",
    "        print(cost_val)     \n",
    "\n",
    "# 학습진행\n",
    "# for step in range(3000):\n",
    "#     _, cost_val = sess.run([train,cost], feed_dict={X:mnist.train.images, Y:mnist.train.labels})\n",
    "    \n",
    "#     if step % 300 == 0:\n",
    "#         print(cost_val)\n",
    "\n",
    "# Accuracy(정확도) 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run([accuracy], feed_dict={X:mnist.test.images, Y:mnist.test.labels})\n",
    "\n",
    "print(\"정확도 :{}\".format(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
